---
title: "Adaptive Divergence Regularized Policy Optimization for Fine-tuning Generative Models"
collection: publications
permalink: /publication/2025-06-01-ADRPO-NeurIPS2025
date: 2025-06-01
venue: 'The Thirty-Ninth Annual Conference on Neural Information Processing Systems (<strong>NeurIPS 2025</strong>)'
paperurl: 'https://openreview.net/forum?id=aXO0xg0ttW'
citation: 'Jiajun Fan, Tong Wei, Chaoran Cheng, Yuxin Chen, Ge Liu. &quot;Adaptive Divergence Regularized Policy Optimization for Fine-tuning Generative Models.&quot; NeurIPS 2025.'
---

We propose ADRPO, which dynamically adjusts divergence regularization strength based on advantage estimates â€” reducing regularization for high-value samples while applying stronger constraints to poor samples. Enables a 2B SD3 model to surpass 4.8B/12B models; also generalizes to LLMs and multimodal reasoning.
