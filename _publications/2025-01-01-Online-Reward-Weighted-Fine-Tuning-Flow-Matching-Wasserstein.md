---
title: "Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization"
collection: publications
permalink: /publication/2025-01-01-ORW-CFM-W2-ICLR2025
date: 2025-01-01
venue: 'International Conference on Learning Representations 2025 (ICLR 2025)'
paperurl: 'https://openreview.net/forum?id=9mrF3MPEDk9'
citation: 'Jiajun Fan, et al. &quot;Online Reward-Weighted Fine-Tuning of Flow Matching with Wasserstein Regularization.&quot; ICLR 2025.'
---

We introduce a self-evolving RLHF framework (ORW-CFM-W2) that enables flow matching models to continuously optimize through online reward feedback without relying on human-collected datasets. We derive a tractable Wasserstein-2 distance bound providing the first theoretical guarantee for collapse-free policy evolution.
